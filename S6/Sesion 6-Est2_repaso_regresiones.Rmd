---
title: "Repaso de regresiones"
author: "Alexander Benites, Chiara Zamora y Airam Bello"
date: "Ciclo 2023-2"
subtitle: 'Curso: POL304 - Estadística para el análisis político 2'
output:
  html_document: default
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r,echo=FALSE, out.width="40%",fig.align="center"}
knitr::include_graphics("logoPUCP.png") 
```

### A. Regresión Lineal (OLS)

El modelo de regresión básico. Evalúa el impacto de una (o varias)
variables independientes (o predictores) sobre una variable dependiente
que debe ser numérica continua.

Vamos a traer una base de datos con los resultados de las ERM del año
2018, solo para los distritos de la provincia de Lima. Los datos ya se
encuentran limpios.

```{r}
library(rio)
dataols = import("https://github.com/Alexanderbenit7/ERM2018/raw/master/finalData.csv")
dataols = dataols[,c(15,1,3,6,9,4,7)]
```

Vamos a cambiar algunos nombres y a sacar la tasa de personas con
discapacidad en el distrito:

```{r}
colnames(dataols) = c("Vote","Dist","Ubigeo","Disc","Pobre","Pop","IVA")
dataols$Dic_porc = dataols$Disc/dataols$Pop
dataols$IVA_cat = factor(ifelse(dataols$IVA>0.173227,1,0))
```

Estas son las variables:

-   Vote: Porcentaje de votos por AP
-   Dist: Nombre del distrito
-   Disc: Número de personas con alguna discapacidad en el disrito
-   Pobre: Porcentaje de personas en situación de pobreza monetaria en
    el distrito
-   IVA: índice de vulnerabilidad alimentaria
-   IVA_cat: Distrito por encima de la media del IVA

Queremos conocer las variables que explicarían el voto por Acción
Popular en los distritos de Lima en esa elección. Imaginen que les piden
comprobar esta hipótesis:

Voto por AP = El porcentaje de personas con discapacidad + El % de
personas en situación de pobreza.

```{r}
reg_ols = lm(Vote ~ Dic_porc + Pobre, data = dataols)
summary(reg_ols)
```

Los resultados del análisis nos muestran lo siguiente:

-   El modelo es válido
-   Hay un buen porcentaje de variable explicado: R2 ajustado de 0.79.
    Es decir, se explica un 80% de la varianza del modelo.
-   El porcentaje de personas con discapacidad en el distrito no
    presenta un impacto estadísticamente significativo el voto por AP a
    nivel distrital
-   El porcentaje de personas en situación de pobreza monetaria tiene un
    efecto estadísticamente positivo e inverso.
-   El aumento de 1 punto en el porcentaje de de personas en situación
    de pobreza en el distrito disminuye el porcentaje del voto por AP en
    1.75%.

Ahora le piden tomar en consideración si el distrito está por encima del
promedio del IVA

```{r}
reg_ols1 = lm(Vote ~ Dic_porc + Pobre + IVA_cat, data = dataols)
summary(reg_ols1)
```

Vemos que el predictor no es estadísticamente significativo, y parece
que no nos cambia mucho el escenario. Podemos comprobarlo:

```{r}
library(magrittr)
library(knitr)
tanova=anova(reg_ols,reg_ols1)

kable(tanova,
      caption = "Tabla ANOVA para comparar modelos")%>%kableExtra::kable_styling(full_width = FALSE)
```

Vemos que el p-valor no es estadísticamente significativo, por lo que no
hay una mejora incluyendo la variable IVA_cat, que en parte ya sabíamos
debido a que no es un predictor estadísticamente significativo.

Y si IVA_cat hubiera sigo estadísticamente significativo, y nos
preguntaran por el predictor que tiene un impacto *mayor*?

```{r}
reg_ols1_st = lm(scale(Vote) ~ scale(Dic_porc) + scale(Pobre) + scale(as.numeric(IVA_cat)), data = dataols)
summary(reg_ols1_st)
```

Veámoslo mejor:

```{r}
library(modelsummary)
modelo_st=list('Voto estandarizado' = reg_ols1_st)
modelsummary(modelo_st, title = "Regresion: modelo con \ncoeficientes estandarizados",
             stars = TRUE,
             output = "kableExtra")
```

Vemos que el porcentaje de pobreza en el distrito sería la variable que
tendría mayor impacto. Ahora miremos los diagnósticos del model:

#### Linealidad:

```{r}
plot(reg_ols1,1)
```

Buscamos una relación lineal entre variables. También podemos sacar el
promedio de los residuos (la diferencia entre el valor esperado y el
observado)

```{r}
mean(reg_ols1$residuals)
```

#### Homocedasticidad:

```{r}
plot(reg_ols1, 3)
```

Buscamos un p-valor mayor a .05. Esto nos muestra que nuestro modelo es
homocedástico. La varianza de los errores es constante y no muestra un
patrón. Esto es bueno!

```{r}
library(lmtest)
bptest(reg_ols1)
```

#### Normalidad de residuos:

```{r}
plot(reg_ols1, 2)
shapiro.test(reg_ols1$residuals)
```

Buscamos un p-valor menor a .05. Esto indica que los residuos (la
distancia entre el valor esperado y el valor observado) se distribuyen
de manera normal.

#### No multicolinealidad:

Que no haya una correlación muy alta entre predictores. Idealmente
menores a 3, aceptable hasta menor a 5.

```{r}
library(DescTools)
VIF(reg_ols1)
```

#### Valores influyentes:

```{r}
plot(reg_ols1, 5)
```

```{r}
check = as.data.frame(influence.measures(reg_ols1)$is.inf)
check[check$cook.d & check$hat,]
```

Sin valores influyentes!

### B. Regresión Poisson (No lineal)

La regresión Poisson tiene sus supuestos:

-   Variable de respuesta es un conteo por unidad de tiempo o espacio,
    que puede ser descrita por la distribución Poisson.

-   Independencia: Las observaciones (filas) no deben tener relación
    entre sí.

-   Media=Varianza: Por definición, la media de una variable que se
    distribuye como Poisson debe ser igual a su varianza.

-   Linealidad: El logaritmo de la media de los datos, log(λ), debe ser
    una función lineal de los datos

Limpieza de la base de datos:

```{r}
data = import("Base - Nacional.sav")
```

```{r}
subdata = data[,c(2,4,5,7,8,15,16,29,82,57,58:63)]
colnames(subdata) = c("SEX","EDAD1","EDAD2","ESTUDIOS1","ESTUDIOS2","VIVIR_FUERA",
                      "FAM_FUERA","BARRIO","NOTICIAS","M_APARIENCIA","M_AMIGABLE",
                      "M_COQUETA","M_OPORTUNISTA","M_SEGURA","M_PROMISCUA","M_ATRACTIVA")
```

```{r}
subdata$VIVIR_FUERA = ifelse(subdata$VIVIR_FUERA == "Sí",1,0)
subdata$VIVIR_FUERA = factor(subdata$VIVIR_FUERA, levels = c(0:1), labels = c("No", "Sí"))
```

```{r}
subdata$M_APARIENCIA = ifelse(subdata$M_APARIENCIA == "Sí",1,0)
subdata$M_AMIGABLE = ifelse(subdata$M_AMIGABLE == "Sí, bastante",1,0)
subdata$M_COQUETA = ifelse(subdata$M_COQUETA == "Sí, bastante",1,0)
subdata$M_OPORTUNISTA = ifelse(subdata$M_OPORTUNISTA == "Sí, bastante",1,0)
subdata$M_SEGURA = ifelse(subdata$M_SEGURA == "Sí, bastante",1,0)
subdata$M_PROMISCUA = ifelse(subdata$M_PROMISCUA == "Sí, bastante",1,0)
subdata$M_ATRACTIVA = ifelse(subdata$M_ATRACTIVA == "Sí, bastante",1,0)
```

La variable dependiente:

```{r}
subdata$vd = subdata$M_APARIENCIA + subdata$M_OPORTUNISTA + subdata$M_PROMISCUA + subdata$M_COQUETA
```

Las independientes:

```{r}
#Genero:
subdata = subdata[subdata$SEX == "Hombre" |
                    subdata$SEX == "Mujer",]

subdata$SEX = ifelse(subdata$SEX == "Hombre",1,0)
subdata$SEX = factor(subdata$SEX, levels = c(0,1), labels = c("Mujer","Hombre"))
```

```{r}
#Comparte el barrio con personas venezolanas:
subdata$BARRIO[subdata$BARRIO == "No sabe / Prefiere no responder"] = NA

subdata$BARRIO = ifelse(subdata$BARRIO == "Sí",1,0) 
subdata$BARRIO = factor(subdata$BARRIO, levels = c(0:1), labels = c("No", "Sí"))
```

```{r}
#Exposición a medios de comunicación:
subdata$NOTICIAS[subdata$NOTICIAS == "No sabe / Prefiere no responder"] = NA 

subdata$NOTICIAS = ifelse(subdata$NOTICIAS == "Nunca",1,
                          ifelse(subdata$NOTICIAS == "Una vez al mes",2,
                          ifelse(subdata$NOTICIAS == "Una vez a la semana",3,
                          ifelse(subdata$NOTICIAS == "3 veces a la semana aprox.",4,
                          ifelse(subdata$NOTICIAS == "Todos los días",5,0)))))

subdata$NOTICIAS = factor(subdata$NOTICIAS, levels = c(1:5),
                          labels = c("Nunca","Una vez al mes","Una vez a la semana",
                                     "Tres veces a la semana","Todos los días"))
```

```{r}
library(fastDummies)
subdata=dummy_cols(subdata, select_columns = c("NOTICIAS"))
```

```{r}
colnames(subdata)[18] = "NUNCA"
colnames(subdata)[19] = "UNA_MES"
colnames(subdata)[20] = "UNA_SEMANA"
colnames(subdata)[21] = "TRES_SEMANA"
colnames(subdata)[22] = "TODOS_DIAS"
```

Le solicitan crear tres modelos para explicar las representaciones
negativas sobre las mujeres migrantes:

-   H1: Se explica por el hecho de que la persona encuestada compara el
    barrio con personas venezolanas (BARRIO)
-   H2: Se explica por el hecho de compartir el barrio (BARRIO) con
    personas venezolanas y el género (SEX)
-   H3: Se explica por esas dos variables y por ver todos los días
    noticias sobre personas migrantes en medios de comunicación
    (TODOS_DIAS)

```{r}
rp1=glm(vd ~ BARRIO, data = subdata, family = poisson(link = "log"))
rp2=glm(vd ~ BARRIO + SEX, data = subdata, family = poisson(link = "log"))
rp3=glm(vd ~ BARRIO + SEX + TODOS_DIAS, data = subdata, family = poisson(link = "log"))
```

```{r}
# displaying results
modelslmpoi=list('POISSON 1'=rp1,
                 'POISSON 2'=rp2,
                 'POISSON 3'=rp3)

modelsummary(modelslmpoi, title = "Regresiones Poisson",
             stars = TRUE,
             output = "kableExtra")
```

¿Qué resultados tenemos, por ejemplo, del segundo modelo?

-   El hecho de compartir barrio con personas venezolanas aumenta la
    probabilidad de adherirse a representaciones negativas de las
    mujeres migrantes
-   El hecho de ser hombre no tiene impactos estadísticamente
    significativos en la probabilidad.

Pero debemos exponenciar los coeficientes:

```{r}
modelsummary(modelslmpoi, title = "Regresiones Poisson",
             stars = TRUE,
             statistic = 'conf.int',
             exponentiate = T, # exponenciar!!!!!
             output = "kableExtra")
```

De forma más sencilla, si quisiéramos el impacto del hecho de compartir
barrio con personas venezolanas sobre la probabilidad en el modelo 2.
Hacemos lo siguiente:

```{r}
exp(coef(rp2)[['BARRIOSí']]) #Personas venezolanas en el barrio
```

```{r}
exp_rp2 = 1-1.167723
exp_rp2 = exp_rp2*-1
exp_rp2
```

```{r}
100*exp_rp2
```

El hecho de compartir el barrio con personas migrantes aumenta la
probabilidad de adherirse a representaciones negativas de mujeres
migrantes en 17%

Y el impacto de ver noticias sobre personas migrantes en medios de
comunicación todos los días:

```{r}
exp(coef(rp3)[['TODOS_DIAS']])
```

El hecho de ver noticias sobre personas migrantes en medios de
comunicación todos los días aumenta la probabilidad de adherirse a
representaciones negativas de mujeres migrantes en 43%

```{r}
exp_rp3 = 1-1.425909
exp_rp3 = exp_rp3*-1
exp_rp3*100
```

Uno de los supuestos en la Regresión Poisson es que la media y la
varianza sean iguales. Veamos:

```{r}
library(magrittr)
overdispersion=AER::dispersiontest(rp3,alternative='greater')$ p.value<0.05
underdispersion=AER::dispersiontest(rp3,alternative='less')$ p.value<0.05
# tabla
testResult=as.data.frame(rbind(overdispersion,underdispersion))
names(testResult)='Es probable?'
testResult%>%kable(caption = "Test de Equidispersión")%>%kableExtra::kable_styling()
```

La prueba nos muestra que es altamente probable que tengamos
subdispersión. Corresponde un modelo quasipoisson:

```{r}
rqp = glm(vd ~ BARRIO + SEX + TODOS_DIAS, data = subdata,
          family = quasipoisson(link = "log"))

modelsPQP=list('POISSON'=rp3,'QUASIPOISSON'=rqp)

modelsummary(modelsPQP, 
             title = "Regresiones Poisson y QuasiPoisson",
             stars = TRUE,
             output = "kableExtra")
```

Observamos una ligera reducción de errores típicos:

```{r}
library(arm)
cbind(se_Poi=se.coef(rp3),se_QuasiPoi=se.coef(rqp))
```

Comparemos ambos modelos:

```{r}
anova(rp3,rqp, test = "Chisq") %>%
kable(caption = "Tabla ANOVA para comparar modelos")%>%kableExtra::kable_styling(full_width = FALSE)
```

En realidad no hay una mejora sustancial en el modelo. Sin embargo, la
binomial negativa (la alternativa que nos queda) no es la más apropiada
en un caso de subdispersión.

### C. Regresión Logística

**Ideas clave**

-   La probabilidad: Es una medida que señala que tan posible es que
    ocurra un fenómeno o evento. Oscila entre 0 y 1. Cuanto más cerca de
    0 menos probabilidad, y cuanto más cerca del 1 indica más
    probabilidad. Ejemplo: la probabilidad de ganar en un partido de
    futbol.

-   Odds: Es la probabilidad de que suceda un evento dividido por la
    probabilidad de que no suceda. Oscilan entre 0 e infinito y se
    pueden calcular para la ocurrencia del evento como para la no
    ocurrencia del evento. Ejemplo: la probabilidad de ganar una apuesta
    en un partido de futbol es 1.5 veces más probable que perder

-   ODDs Ratio: Es la razón entre dos odds. Permite comparar los odds de
    un evento en dos grupos Va de 0 a infinito. Los modelos de regresión
    logística están basados en probabilidades entre dos variables. Por
    esta razón, es útil conocer los ODDs ratio. Ejemplo: Ganar en una
    apuesta de un partido de futbol es 5 veces más probable que el ganar
    en una apuesta de voley

-   La regresión logística modela el comportamiento de la probabilidad
    del evento de interés. Es un tipo de análisis de regresión utilizado
    para predecir el resultado de una variable categórica (dependiente)
    en función de las variables predictoras (independientes). Es útil
    para modelar la probabilidad de que ocurra un evento en función del
    efecto de un conjunto de variables.

-   La idea es que la regresión logística aproxime la probabilidad de
    obtener "0" (no ocurre cierto suceso) o "1" (ocurre el suceso) con
    el valor de la variable explicativa x.

Modelemos la probabilidad de que una persona considere que las mujeres
venezolanas consiguen trabajo por su apariencia:

```{r}
table(subdata$M_APARIENCIA)
```

¿Está relacionado ello con el género de la persona encuestada?

```{r}
dep=subdata$M_APARIENCIA # a la fila
ind=subdata$SEX # a la columna

NarrsexTable=table(dep,ind,dnn = c('Narrative','Gender'))

### suma por fila y columna
addmargins(NarrsexTable)%>%
    kable(caption = "Tabla de Contingencia: 'Género' y 'Creer la narrativa'")%>%
    kableExtra::kable_styling(full_width = F)
```

La probabilidad que una mujer crea la narrativa

```{r}
ProbMujNarr=NarrsexTable[2,1]/sum(NarrsexTable[,1])
MASS::fractions(ProbMujNarr)
ProbMujNarr
```

Representemos el ODDS de creerlo con respecto a quienes no lo creen

```{r}
OddsMujNarr=NarrsexTable[2,1]/NarrsexTable[1,1]
MASS::fractions(OddsMujNarr)
OddsMujNarr
```

O lo que es lo mismo:

```{r}
ProbMujNarr/(1-ProbMujNarr)
```

Ahora saquemos el ODDS Ratio (en función al hombre)

```{r}
ProbHombNarr=NarrsexTable[2,2]/sum(NarrsexTable[,2])
OddsHombNarr = ProbHombNarr/(1-ProbHombNarr)
```

ODDS ratio:

```{r}
(OR_MujHom=OddsMujNarr/OddsHombNarr)
```

Un factor de .05. Prácticamente no hay diferencias.

```{r}
mosaicplot( t(NarrsexTable),col = c("orange", "green"),main = "")
```

Veamos si hay diferencias estadísticamente significativas:

```{r}
set.seed(2023)

### first hypothesis
h1=formula(M_APARIENCIA~SEX)

#regression
rlog1=glm(h1, data=subdata,family = binomial)
modelrl=list('Trabajo por su apariencia'=rlog1)

#f <- function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelrl,
             title = "Regresión Logística",
             stars = TRUE,
             output = "kableExtra")
```

Y lo comprobamos en la medida que no hay impactos estadísticamente
significativos.

Probemos estas hipotesis. La adhesión a esta narrativa se explica por:

-   H1: El género (SEX) y la edad (EDAD1)
-   H2: El género (SEX), la edad (EDAD1) y haber vivido fuera del país
    (VIVIR_FUERA)
-   H3: El género (SEX), la edad (EDAD1), haber vivido fuera del país
    (VIVIR_FUERA) y la exposición a medios de comunicación diaria a
    medios de comunicación (TODOS_DIAS)

```{r}
h1=formula(M_APARIENCIA ~ SEX + EDAD1)
h2=formula(M_APARIENCIA ~ SEX + EDAD1 + VIVIR_FUERA)
h3=formula(M_APARIENCIA ~ SEX + EDAD1 + VIVIR_FUERA + TODOS_DIAS)
```

```{r}
rlog1=glm(h1, data=subdata,family = binomial)
rlog2=glm(h2, data=subdata,family = binomial)
rlog3=glm(h3, data=subdata,family = binomial)
```

```{r}
summary(rlog1)
```

```{r}
summary(rlog2)
```

```{r}
summary(rlog3)
```

```{r}
modelsrl=list('Adhesión (I)'=rlog1,
             'Adhesión (II)'=rlog2,
             'Adhesión (III)'=rlog3)

# formato creado para modelsummary
formatoNumero = function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsrl,
             fmt=formatoNumero, # usa función que creé antes
             exponentiate = T, # coeficientes sin logaritmo
             statistic = 'conf.int', # mostrar ICs
             title = "Regresión Logísticas (Coeficientes Exponenciados)",
             stars = TRUE,
             output = "kableExtra")
```

De este modelo, el principal hallazgo es que solo el modelo 3 presenta
una variable estadísticamente significativa: ver noticias sobre personas
migrantes todos los días en medios de comunicación.

Esto, sin embargo, es dificil de interpretar. Calculemos los efectos
marginales:

```{r}
library(margins)
marginalsData=summary(margins(rlog3))
marginalsData%>% kable(caption = "Efectos Marginales Promedio (AME)- Modelo III") %>%kableExtra::kable_styling(full_width = T)
```

Ahora sabemos que el hecho de ver todos los días estas noticias aumenta
la probabilidad de adherirse a la narrativa en .16 (o 16%).

### D. Regresión Cox

El objetivo de la regresión Cox es evaluar los impactos de diferentes
variables sobre la "sobrevivencia". Es decir, nos ayuda a saber si
ciertos factores influecian la tasa de ocurrencia de un evento en
específico en un lapso de tiempo.

```{r}
library(survival)
library(survminer)
```

Vamos a trabajar con una base de datos de personas con cancer al pulmón:

```{r}
head(lung)
```

Estas son las variables:

inst: Institution code time: Survival time in days status: censoring
status 1=censored, 2=dead age: Age in years sex: Male=1 Female=2
ph.ecog: ECOG performance score (0=good 5=dead) ph.karno: Karnofsky
performance score (bad=0-good=100) rated by physician pat.karno:
Karnofsky performance score as rated by patient meal.cal: Calories
consumed at meals wt.loss: Weight loss in last six months

Vamos a ver algunos descriptivos del tiempo de sobrevivencia:

```{r}
summary(lung$time)
```

Ahora de la ocurrencia del evento:

```{r}
#Recodificamos para que 0 sea la ocurrencia:
lung$status1 = ifelse(lung$status == 2,1,0)
table(lung$status1)
```

Empezamos con el análisis:

```{r}
lung$survival=with(lung,Surv(time = time,
                             event =  status1))
```

```{r}
library(ggplot2)
library(ggfortify)

KM.generico = survfit(survival ~ 1, data = lung)

ejeX='DAYS\n Curva cae cuando ocurre un fallecimiento'
ejeY='Probabilidad \n(Sobrevivir)'
titulo="Curva de Sobrevivencia"
autoplot(KM.generico,xlab=ejeX,ylab=ejeY, main = titulo,conf.int = F)
```

Lo que indica el gráfico es que la probabilidad de sobrevivir al cancer
en el día 0 es del 100% (todas las personas del estudio están vivas).
Esta diminuye conforme avanzan los días. Pasado el día número 500, la
probabilidad de sobrevivir es menor al 25%.

Ahora probemos una hipótesis: los hombres tienen una menor probabilidad
de sobrevivir.

```{r}
KM_H1=formula(survival ~ sex)

KM.sex = survfit(KM_H1, data = lung)

###
ejeX='DAYS\n Curva cae cuando ocurre un fallecimiento'
ejeY='Probabilidad \n(Sobrevivir)'
titulo="Curva de Sobrevivencia"

autoplot(KM.sex,xlab=ejeX,ylab=ejeY, 
         main = titulo,conf.int = F)  + 
        labs(colour = "Impacto del género") + 
         scale_color_discrete(labels = c("Hombre", "Mujer"))
```

Efectivamente, parece que la mejor no pinta tan bien para los hombres.
Veamos los intervalos de confianza:

```{r}
LogRank=survdiff(KM_H1, data = lung)
LogRank$pvalue
```

```{r}
autoplot(KM.sex,xlab=ejeX,ylab=ejeY, 
         main = titulo,conf.int = T)+ 
        labs(colour = "Impacto del género") + 
         scale_color_discrete(labels = c("Hombre", "Mujer"))
```

Probemos ahora otra hipótesis: más joven es la persona, sus probabilidad
de sobrevivir serán mayores. Para ver cómo juegan ambas variables a la
vez, hay que evaluarlo con una regresión:

```{r}
COX_H1= formula(survival~factor(sex)+age)
rcox1 <- coxph(COX_H1,data=lung)
summary(rcox1)
```

Vemos que el género tiene un impacto negativo sobre la probabilidad de
fallecimiento. Es decir, el ser mujer (2) disminuye la probabilidad de
ocurrencia del evento. Esto es estadísticamente significativo, mientras
que la edad no muestra impactos. Pero, en tanto esta es una combinación
lineal, no se pueden interpretar directamente:

```{r}
(sex=abs(1-exp(coef(rcox1)[1])))
```

Esto ya se puede interpretar: ser mujer está asociado con un mejor
pronóstico, reduciendo las probabilidades de ocurrencia del evento en
40%.
